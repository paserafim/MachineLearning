{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "dPpJUV862FYI",
        "i2e3TlyL57Qs",
        "wCugvl0JdWYL"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/paserafim/MachineLearning/blob/master/logistic_regression.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4T-_IsVbweU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "LEAHZv4rIYHX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Reframe the median house value predictor (from the preceding exercises) as a binary classification model\n",
        "  * Compare the effectiveness of logisitic regression vs linear regression for a binary classification problem"
      ]
    },
    {
      "metadata": {
        "id": "CnkCZqdIIYHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As in the prior exercises, we're working with the [California housing data set](https://developers.google.com/machine-learning/crash-course/california-housing-data-description), but this time we will turn it into a binary classification problem by predicting whether a city block is a high-cost city block. We'll also revert to the default features, for now."
      ]
    },
    {
      "metadata": {
        "id": "9pltCyy2K3dd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Frame the Problem as Binary Classification\n",
        "\n",
        "The target of our dataset is `median_house_value` which is a numeric (continuous-valued) feature. We can create a boolean label by applying a threshold to this continuous value.\n",
        "\n",
        "Given features describing a city block, we wish to predict if it is a high-cost city block. To prepare the targets for train and eval data, we define a classification threshold of the 75%-ile for median house value (a value of approximately 265000). All house values above the threshold are labeled `1`, and all others are labeled `0`."
      ]
    },
    {
      "metadata": {
        "id": "67IJwZX1Vvjt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Run the cells below to load the data and prepare the input features and targets."
      ]
    },
    {
      "metadata": {
        "id": "fOlbcJ4EIYHd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "44580399-8991-4047-ebae-39ad96539535"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "california_housing_dataframe = pd.read_csv(\"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "\n",
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTB73MNeIYHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note how the code below is slightly different from the previous exercises. Instead of using `median_house_value` as target, we create a new binary target, `median_house_value_is_high`."
      ]
    },
    {
      "metadata": {
        "id": "kPSqspaqIYHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5db8bcd8-f29b-4ab0-cd30-6cb5b84c9c25"
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(california_housing_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = california_housing_dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy()\n",
        "  # Create a synthetic feature.\n",
        "  processed_features[\"rooms_per_person\"] = (\n",
        "    california_housing_dataframe[\"total_rooms\"] /\n",
        "    california_housing_dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(california_housing_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  # Create a boolean categorical feature representing whether the\n",
        "  # median_house_value is above a set threshold.\n",
        "  output_targets[\"median_house_value_is_high\"] = (\n",
        "    california_housing_dataframe[\"median_house_value\"] > 265000).astype(float)\n",
        "  return output_targets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwOYWmXqWA6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1209
        },
        "outputId": "ac47683c-1f73-4c3f-b349-bd30cdd2c990"
      },
      "cell_type": "code",
      "source": [
        "# Choose the first 12000 (out of 17000) examples for training.\n",
        "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
        "\n",
        "# Choose the last 5000 (out of 17000) examples for validation.\n",
        "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
        "\n",
        "# Double-check that we've done the right thing.\n",
        "print \"Training examples summary:\"\n",
        "display.display(training_examples.describe())\n",
        "print \"Validation examples summary:\"\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print \"Training targets summary:\"\n",
        "display.display(training_targets.describe())\n",
        "print \"Validation targets summary:\"\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count   12000.0    12000.0             12000.0      12000.0         12000.0   \n",
              "mean       35.6     -119.6                28.6       2654.2           541.9   \n",
              "std         2.1        2.0                12.6       2215.7           427.5   \n",
              "min        32.5     -124.3                 1.0          2.0             2.0   \n",
              "25%        33.9     -121.8                18.0       1462.0           296.0   \n",
              "50%        34.2     -118.5                29.0       2125.0           433.0   \n",
              "75%        37.7     -118.0                37.0       3162.2           655.0   \n",
              "max        42.0     -114.3                52.0      37937.0          6445.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count     12000.0     12000.0        12000.0           12000.0  \n",
              "mean       1432.9       503.3            3.9               2.0  \n",
              "std        1172.9       389.0            1.9               1.2  \n",
              "min           3.0         2.0            0.5               0.1  \n",
              "25%         789.0       281.0            2.6               1.5  \n",
              "50%        1167.0       408.5            3.5               1.9  \n",
              "75%        1725.2       609.0            4.8               2.3  \n",
              "max       35682.0      6082.0           15.0              55.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.6</td>\n",
              "      <td>2654.2</td>\n",
              "      <td>541.9</td>\n",
              "      <td>1432.9</td>\n",
              "      <td>503.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2215.7</td>\n",
              "      <td>427.5</td>\n",
              "      <td>1172.9</td>\n",
              "      <td>389.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1462.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>789.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2125.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>408.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3162.2</td>\n",
              "      <td>655.0</td>\n",
              "      <td>1725.2</td>\n",
              "      <td>609.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    5000.0     5000.0              5000.0       5000.0          5000.0   \n",
              "mean       35.6     -119.6                28.6       2618.4           533.4   \n",
              "std         2.1        2.0                12.6       2091.6           406.8   \n",
              "min        32.5     -124.3                 1.0          8.0             1.0   \n",
              "25%        33.9     -121.8                18.0       1463.0           297.0   \n",
              "50%        34.2     -118.5                29.0       2137.0           435.0   \n",
              "75%        37.7     -118.0                37.0       3129.5           636.0   \n",
              "max        41.8     -114.6                52.0      25957.0          4798.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count      5000.0      5000.0         5000.0            5000.0  \n",
              "mean       1421.7       496.1            3.9               2.0  \n",
              "std        1085.6       373.5            1.9               1.1  \n",
              "min           9.0         1.0            0.5               0.0  \n",
              "25%         790.8       282.0            2.6               1.5  \n",
              "50%        1167.5       410.0            3.6               1.9  \n",
              "75%        1712.2       590.2            4.8               2.3  \n",
              "max       11956.0      4490.0           15.0              34.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.6</td>\n",
              "      <td>2618.4</td>\n",
              "      <td>533.4</td>\n",
              "      <td>1421.7</td>\n",
              "      <td>496.1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2091.6</td>\n",
              "      <td>406.8</td>\n",
              "      <td>1085.6</td>\n",
              "      <td>373.5</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1463.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>790.8</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2137.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>1167.5</td>\n",
              "      <td>410.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3129.5</td>\n",
              "      <td>636.0</td>\n",
              "      <td>1712.2</td>\n",
              "      <td>590.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.8</td>\n",
              "      <td>-114.6</td>\n",
              "      <td>52.0</td>\n",
              "      <td>25957.0</td>\n",
              "      <td>4798.0</td>\n",
              "      <td>11956.0</td>\n",
              "      <td>4490.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>34.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                     12000.0\n",
              "mean                          0.2\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           0.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value_is_high\n",
              "count                      5000.0\n",
              "mean                          0.3\n",
              "std                           0.4\n",
              "min                           0.0\n",
              "25%                           0.0\n",
              "50%                           0.0\n",
              "75%                           1.0\n",
              "max                           1.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value_is_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uon1LB3A31VN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How Would Linear Regression Fare?\n",
        "To see why logistic regression is effective, let us first train a naive model that uses linear regression. This model will use labels with values in the set `{0, 1}` and will try to predict a continuous value that is as close as possible to `0` or `1`. Furthermore, we wish to interpret the output as a probability, so it would be ideal if the output will be within the range `(0, 1)`. We would then apply a threshold of `0.5` to determine the label.\n",
        "\n",
        "Run the cells below to train the linear regression model using [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor)."
      ]
    },
    {
      "metadata": {
        "id": "smmUYRDtWOV_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7ec7547d-b07f-4c22-bf72-536604d8cc20"
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\"\n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5OwSrr1yIKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "40db3f8f-cfe7-4aa2-dada-08990924b75c"
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                            \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SE2-hq8PIYHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8f1e5090-e1ca-437b-f035-3c3af4e61e48"
      },
      "cell_type": "code",
      "source": [
        "def train_linear_regressor_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "    \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print \"Training model...\"\n",
        "  print \"RMSE (on training data):\"\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    \n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print \"  period %02d : %0.2f\" % (period, training_root_mean_squared_error)\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print \"Model training finished.\"\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_regressor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDBD8xeeIYH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "d0cd74db-0db5-435b-ca5f-9588ca967390"
      },
      "cell_type": "code",
      "source": [
        "linear_regressor = train_linear_regressor_model(\n",
        "    learning_rate=0.000001,\n",
        "    steps=200,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 0.45\n",
            "  period 01 : 0.45\n",
            "  period 02 : 0.44\n",
            "  period 03 : 0.44\n",
            "  period 04 : 0.45\n",
            "  period 05 : 0.45\n",
            "  period 06 : 0.44\n",
            "  period 07 : 0.44\n",
            "  period 08 : 0.44\n",
            "  period 09 : 0.44\n",
            "Model training finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGACAYAAACgBBhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncf4/C+6TIy5qtSsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5f2db62fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JjBZ_q7aD9gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Can We Calculate LogLoss for These Predictions?\n",
        "\n",
        "**Examine the predictions and decide whether or not we can use them to calculate LogLoss.**\n",
        "\n",
        "`LinearRegressor` uses the L2 loss, which doesn't do a great job at penalizing misclassifications when the output is interpreted as a probability.  For example, there should be a huge difference whether a negative example is classified as positive with a probability of 0.9 vs 0.9999, but L2 loss doesn't strongly differentiate these cases.\n",
        "\n",
        "In contrast, `LogLoss` penalizes these \"confidence errors\" much more heavily.  Remember, `LogLoss` is defined as:\n",
        "\n",
        "$$Log Loss = \\sum_{(x,y)\\in D} -y \\cdot log(y_{pred}) - (1 - y) \\cdot log(1 - y_{pred})$$\n",
        "\n",
        "\n",
        "But first, we'll need to obtain the prediction values. We could use `LinearRegressor.predict` to obtain these.\n",
        "\n",
        "Given the predictions and that targets, can we calculate `LogLoss`?"
      ]
    },
    {
      "metadata": {
        "id": "dPpJUV862FYI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to display the solution."
      ]
    },
    {
      "metadata": {
        "id": "kXFQ5uig2RoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "0674ef1e-8889-4553-8ac0-411cba988c75"
      },
      "cell_type": "code",
      "source": [
        "predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                  validation_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "\n",
        "validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "\n",
        "_ = plt.hist(validation_predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFKCAYAAAA9s3fqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5f2d19f190>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rYpy336F9wBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Train a Logistic Regression Model and Calculate LogLoss on the Validation Set\n",
        "\n",
        "To use logistic regression, simply use [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) instead of `LinearRegressor`. Complete the code below.\n",
        "\n",
        "**NOTE**: When running `train()` and `predict()` on a `LinearClassifier` model, you can access the real-valued predicted probabilities via the `\"probabilities\"` key in the returned dict—e.g., `predictions[\"probabilities\"]`. Sklearn's [log_loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) function is handy for calculating LogLoss using these probabilities.\n"
      ]
    },
    {
      "metadata": {
        "id": "JElcb--E9wBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5ae9a500-dadc-42a4-b62e-2a49ad3ed4ad"
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_classifier = # YOUR CODE HERE: Construct the linear classifier.\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print \"Training model...\"\n",
        "  print \"LogLoss (on training data):\"\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print \"  period %02d : %0.2f\" % (period, training_log_loss)\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print \"Model training finished.\"\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier\n",
        "\n",
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-f8b72d3cf7f0>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    linear_classifier = # YOUR CODE HERE: Construct the linear classifier.\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VM0wmnFUIYH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2e3TlyL57Qs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below to see the solution.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5YxXd2hn6MuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_linear_classifier_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear classification model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearClassifier` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a linear classifier object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \n",
        "  linear_classifier = tf.estimator.LinearClassifier(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value_is_high\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value_is_high\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value_is_high\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print \"Training model...\"\n",
        "  print \"LogLoss (on training data):\"\n",
        "  training_log_losses = []\n",
        "  validation_log_losses = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_classifier.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.    \n",
        "    training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n",
        "    training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n",
        "    \n",
        "    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n",
        "    \n",
        "    training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n",
        "    validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n",
        "    # Occasionally print the current loss.\n",
        "    print \"  period %02d : %0.2f\" % (period, training_log_loss)\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_log_losses.append(training_log_loss)\n",
        "    validation_log_losses.append(validation_log_loss)\n",
        "  print \"Model training finished.\"\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"LogLoss\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"LogLoss vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_log_losses, label=\"training\")\n",
        "  plt.plot(validation_log_losses, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPM_T1FXsTaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nRHbSdz4us9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-Xo83_aR6s_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Calculate Accuracy and plot a ROC Curve for the Validation Set\n",
        "\n",
        "A few of the metrics useful for classification are the model [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification), the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) and the area under the ROC curve (AUC). We'll examine these metrics.\n",
        "\n",
        "`LinearClassifier.evaluate` calculates useful metrics like accuracy and AUC."
      ]
    },
    {
      "metadata": {
        "id": "DKSQ87VVIYIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print \"AUC on the validation set: %0.2f\" % evaluation_metrics['auc']\n",
        "print \"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47xGS2uNIYIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may use class probabilities, such as those calculated by `LinearClassifier.predict`,\n",
        "and Sklearn's [roc_curve](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) to\n",
        "obtain the true positive and false positive rates needed to plot a ROC curve."
      ]
    },
    {
      "metadata": {
        "id": "xaU7ttj8IYIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n",
        "# Get just the probabilities for the positive class.\n",
        "validation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
        "    validation_targets, validation_probabilities)\n",
        "plt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\n",
        "plt.plot([0, 1], [0, 1], label=\"random classifier\")\n",
        "_ = plt.legend(loc=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIdhwfgzIYII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**See if you can tune the learning settings of the model trained at Task 2 to improve AUC.**\n",
        "\n",
        "Often times, certain metrics improve at the detriment of others, and you'll need to find the settings that achieve a good compromise.\n",
        "\n",
        "**Verify if all metrics improve at the same time.**"
      ]
    },
    {
      "metadata": {
        "id": "XKIqjsqcCaxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TUNE THE SETTINGS BELOW TO IMPROVE AUC\n",
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000005,\n",
        "    steps=500,\n",
        "    batch_size=20,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print \"AUC on the validation set: %0.2f\" % evaluation_metrics['auc']\n",
        "print \"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCugvl0JdWYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a possible solution."
      ]
    },
    {
      "metadata": {
        "id": "VHosS1g2aetf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One possible solution that works is to just train for longer, as long as we don't overfit. \n",
        "\n",
        "We can do this by increasing the number the steps, the batch size, or both.\n",
        "\n",
        "All metrics improve at the same time, so our loss metric is a good proxy\n",
        "for both AUC and accuracy.\n",
        "\n",
        "Notice how it takes many, many more iterations just to squeeze a few more \n",
        "units of AUC. This commonly happens. But often even this small gain is worth \n",
        "the costs."
      ]
    },
    {
      "metadata": {
        "id": "dWgTEYMddaA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_classifier = train_linear_classifier_model(\n",
        "    learning_rate=0.000003,\n",
        "    steps=20000,\n",
        "    batch_size=500,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)\n",
        "\n",
        "evaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n",
        "\n",
        "print \"AUC on the validation set: %0.2f\" % evaluation_metrics['auc']\n",
        "print \"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}